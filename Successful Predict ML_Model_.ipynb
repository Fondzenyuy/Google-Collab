{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fondzenyuy/Google-Collab/blob/main/Successful%20Predict%20ML_Model_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xPajlkVKrIo"
      },
      "source": [
        "# Loading Data&Inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eWjx8VKyJjUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLlICkujEeDh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install optuna # for hyperparameter tuning"
      ],
      "metadata": {
        "id": "2fceV-lVJjRM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGhezyrnidkv",
        "outputId": "3a66f3fe-9972-4906-9e23-dd4e4c48a20a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f665798f730>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import sys, os, time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#import optuna\n",
        "#from optuna.trial import TrialState\n",
        "import torch\n",
        "import torchvision # torch package for vision related things\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "from torch.nn.functional import normalize\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
        "#from tqdm import tqdm  # For nice progress bar!\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGMf1Cy9Ky60",
        "outputId": "7e2c70d4-c285-49f3-fcc3-f21350492cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 14 22:09:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwKcdzRJKiGR",
        "outputId": "52b3022b-23fa-4b12-b4a3-e8ff60f7a13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__CUDNN VERSION: 8302\n",
            "__Number CUDA Devices: 1\n",
            "__CUDA Device Name: Tesla P100-PCIE-16GB\n",
            "__CUDA Device Total Memory [GB]: 17.071734784\n"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
        "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
        "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKvhmyZCvi0Z",
        "outputId": "9b25ce9a-5085-414e-e125-4a05b55cded0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "atqXRdQrKiTx"
      },
      "outputs": [],
      "source": [
        "class Data(Dataset):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, N_SAMPLES = 10000, noise_std=1, train=True):\n",
        "        self.len = N_SAMPLES\n",
        "        self.x = (torch.linspace(-1, 1, N_SAMPLES).view(-1, 1))\n",
        "        min_x, max_x = torch.min(self.x), torch.max(self.x)\n",
        "        self.x = self.x/(max_x - min_x)\n",
        "\n",
        "        self.f = ((self.x)*torch.sin(20*self.x) - ((self.x)**2)*torch.cos(10*self.x))  #key function in model for outputs\n",
        "        min_f , max_f = torch.min(self.f), torch.max(self.f)\n",
        "        self.f = self.f/(max_f - min_f)\n",
        "\n",
        "\n",
        "\n",
        "        if train != True:\n",
        "            torch.manual_seed(1)\n",
        "            self.y = self.f \n",
        "            self.y = self.y.view(-1, 1)\n",
        "            #self.y = (self.y).to(device)\n",
        "            torch.manual_seed(1)\n",
        "        else:\n",
        "            self.y = self.f \n",
        "            self.y = self.y.view(-1, 1)\n",
        "            #self.y = (self.y).to(device)\n",
        "            \n",
        "    # Getter\n",
        "    def __getitem__(self, index):    \n",
        "        return self.x[index], self.y[index]\n",
        "    \n",
        "    # Get Length\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zwFCqc67KiK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24f04eb-9d91-4225-8f17-da69343157f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data_set = Data()\n",
        "len(data_set)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4CjkT9wx0I55"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(data_set, shuffle= True, batch_size = batch_size)\n",
        "validation_loader = DataLoader(Data(train= False), shuffle = True, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "PyDP8hJ8PSlV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyp Param Tuning (Trial 2)"
      ],
      "metadata": {
        "id": "kL3pV3MbsB4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import optuna\n",
        "optuna.logging.disable_default_handler()\n",
        "\n",
        "\n",
        "\n",
        "# Build neural network model\n",
        "# Simple CNN\n",
        "class Net(nn.Module):\n",
        "    # Constructor\n",
        "    def __init__(self, in_size, n_hidden, out_size, p=0.5):\n",
        "      super(Net, self).__init__()\n",
        "      self.drop = nn.Dropout(p=p)\n",
        "      self.linear1 = nn.Linear(in_size, n_hidden)\n",
        "      self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
        "      self.linear3 = nn.Linear(n_hidden, out_size)\n",
        "\n",
        "      \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "      # x = F.relu(self.drop(self.linear1(x))).to(device)\n",
        "      \n",
        "      x = self.linear1(x)\n",
        "      x = self.drop(x)\n",
        "      x = F.relu(x)\n",
        "\n",
        "      x = F.relu(self.drop(self.linear2(x)))\n",
        "      x = self.linear3(x)\n",
        "      return x\n",
        "\n",
        "# Initialize network\n",
        "\n",
        "model = Net(1,100,1, p =0.5).to(device)  "
      ],
      "metadata": {
        "id": "_jm1jMrxr_5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model, device, train_loader, optimizer):\n",
        "  model.train()\n",
        "  for x,y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = F.nll_loss(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "def test(model, device, validation_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in validation_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output = model(x)\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "    return 1 - correct / len(validation_loader.dataset)"
      ],
      "metadata": {
        "id": "ZnJbaD8Pr_7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iEtPF0eTr_9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n41zvvU6uIcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model_name: str = \"resnet18\"):  \n",
        "    if model_name == \"resnet18\":\n",
        "        model = torchvision.models.resnet18(pretrained=True)\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_features, 2)\n",
        "    elif model_name == \"alexnet\":\n",
        "        model = torchvision.models.alexnet(pretrained=True)\n",
        "        in_features = model.classifier[1].in_features\n",
        "        model.classifier = nn.Linear(in_features, 2)\n",
        "    elif model_name == \"vgg16\":\n",
        "        model = torchvision.models.vgg16(pretrained=True)\n",
        "        in_features = model.classifier[0].in_features\n",
        "        model.classifier = nn.Linear(in_features, 2)\n",
        "    return model"
      ],
      "metadata": {
        "id": "qj8DiRuD2EJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sampler = optuna.samplers.TPESampler()    \n",
        "study = optuna.create_study(\n",
        "    sampler=sampler,\n",
        "    pruner=optuna.pruners.MedianPruner(\n",
        "        n_startup_trials=2, n_warmup_steps=5, interval_steps=3\n",
        "    ),\n",
        "    direction='minimize')\n",
        "study.optimize(func=objective, n_trials=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "UDIWnF2LuIgL",
        "outputId": "f659e2f7-9c43-446a-9b38-7e693a0de89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trial 0 failed because of the following error: TypeError(\"trainhyp() missing 1 required positional argument: 'criterion'\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-129-dd9e8fe8f960>\", line 51, in objective\n",
            "    best_model = trainhyp(trial, model, criterion, optimizer, num_epochs=20)\n",
            "TypeError: trainhyp() missing 1 required positional argument: 'criterion'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-a8e285475afd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     ),\n\u001b[1;32m      8\u001b[0m     direction='minimize')\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-129-dd9e8fe8f960>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Train a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainhyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Return accuracy (Objective Value) of the current trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: trainhyp() missing 1 required positional argument: 'criterion'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LPR7cF37uIiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mcaGTbMS0q2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z5n5NoMT0q4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rH-UH31_0q6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LRhCUGuS0q8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Do6vCEE80q-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SSwqEm3hsAAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zOpERaN2sACI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HeiX7mdcsAFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "PITV0c-CKNau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each of Optuna hyperparameter tuning session is called `study` . We instantiate a study session by calling `create_study` method. We can pass a couple of important arguments into this method as follows."
      ],
      "metadata": {
        "id": "cKOq_IFxKoI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tT4m9Ng6KL_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we pass direction and sampler variables as arguments into create_study method.\n",
        "#study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler()) \n",
        "#study.optimize(objective, n_trials=30)    #objective function is gotten by defining the search space.\n",
        "#Search space is the range of value that the sampler should consider from a hyperparameter.\n"
      ],
      "metadata": {
        "id": "pVpNY_6DKMBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build neural network model\n",
        "# Simple CNN\n",
        "class Net(nn.Module):\n",
        "    # Constructor\n",
        "    def __init__(self, in_size, n_hidden, out_size, p=0.5):\n",
        "      super(Net, self).__init__()\n",
        "      self.drop = nn.Dropout(p=p)\n",
        "      self.linear1 = nn.Linear(in_size, n_hidden)\n",
        "      self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
        "      self.linear3 = nn.Linear(n_hidden, out_size)\n",
        "\n",
        "      \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "      # x = F.relu(self.drop(self.linear1(x))).to(device)\n",
        "      \n",
        "      x = self.linear1(x)\n",
        "      x = self.drop(x)\n",
        "      x = F.relu(x)\n",
        "\n",
        "      x = F.relu(self.drop(self.linear2(x)))\n",
        "      x = self.linear3(x)\n",
        "      return x\n",
        "#Initialize network\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "modelhyp = Net(1, 100, 1, p=0.5).to(device)\n",
        " \n",
        "# Train and evaluate the accuarcy of neural network model\n",
        "def train_and_evaluate(param, model):\n",
        "    \n",
        "    \n",
        "    \n",
        "    #train_data, val_data = train_test_split(df, test_size = 0.2, random_state = 42)\n",
        "    train_loader = DataLoader(data_set, shuffle= True) #, batch_size = 2) #batch_size)\n",
        "    validation_loader = DataLoader(Data(train= False), shuffle = True) #, batch_size = 2) #batch_size = batch_size)\n",
        "    #train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    \n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(EPOCHS):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for x,y in train_loader:\n",
        "\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                output = model(x, return_dict=False)\n",
        "                \n",
        "                batch_loss = criterion(output, y)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == y).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                modelhyp.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for x, y in validation_loader:\n",
        "\n",
        "                    x = x.to(device)\n",
        "                    y = y.to(device)\n",
        "\n",
        "                    output = model(x)\n",
        "\n",
        "                    batch_loss = criterion(output, y)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == y).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            accuracy = total_acc_val/len(data_set)\n",
        "\n",
        "    return accuracy\n",
        "  \n",
        " # Define a set of hyperparameter values, build the model, train the model, and evaluate the accuracy \n",
        "def objective(trial):\n",
        "  #generate the model\n",
        "  model = modelhyp(trial).to(device)\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  lr = trial.suggest_float('learning_rate', 1e-5, 1e-1)\n",
        "  optimizer = getattr(optim, optimizer_name)(modelhyp.parameters(), lr= lr)\n",
        "\n",
        "\n",
        "  #model training\n",
        "  \n",
        "  for epoch in range(EPOCHS):\n",
        "    trial.report(accuracy,epoch)\n",
        "\n",
        "    #handle pruning based on the intermediate value\n",
        "    if trial.should_prune():\n",
        "      raise optuna.exceptions.Trial_Pruned()\n",
        "\n",
        "    \n",
        "     \n",
        "    \n",
        "     #accuracy = train_and_evaluate(params, modelhyp, trial)\n",
        "\n",
        "return accuracy"
      ],
      "metadata": {
        "id": "VEDgo8nQKMED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run hyperparams tuning\n",
        "\n",
        "EPOCHS = 2\n",
        "    \n",
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "QLnce7BOKMGp",
        "outputId": "dc66167c-9770-4a58-ed44-670afe3a2940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-04 20:53:59,290]\u001b[0m A new study created in memory with name: no-name-ac65859e-5b83-4bf6-83aa-7146d9971aa9\u001b[0m\n",
            "\u001b[33m[W 2022-08-04 20:53:59,293]\u001b[0m Trial 0 failed because of the following error: TypeError(\"linear(): argument 'input' (position 1) must be Tensor, not dict\")\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-47-1f7214681150>\", line 106, in objective\n",
            "    model = modelhyp(params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"<ipython-input-47-1f7214681150>\", line 19, in forward\n",
            "    x = self.linear1(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "TypeError: linear(): argument 'input' (position 1) must be Tensor, not dict\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-e2ead2730b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-1f7214681150>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    104\u001b[0m               }\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m      \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelhyp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m      \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-1f7214681150>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;31m# x = F.relu(self.drop(self.linear1(x))).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not dict"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9pFAS7jpqWp",
        "outputId": "5dc9da15-991a-40f6-a132-43537910a897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ttxK7RmIU-l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1ec1Y8FhKMJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-sTfMFQCKMLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "st2sfUCYKMNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UXoPSQOTKMPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6OmkwWfUKMR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iJ31u-IKKMUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VWDQAyGrKMWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Hyperparameters"
      ],
      "metadata": {
        "id": "Z5kAZRdJPxge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample Hyperparameters\n",
        "\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "#num_epochs = 1200"
      ],
      "metadata": {
        "id": "TIFAN_VCm1JV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveBestModel:\n",
        "    \"\"\"\n",
        "    Class to save the best model while training. If the current epoch's \n",
        "    validation loss is less than the previous least less, then save the\n",
        "    model state.\n",
        "    \"\"\"\n",
        "    def __init__(self, best_valid_loss= 1e6)    :     #float('inf'))\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "        \n",
        "    def __call__(self, current_valid_loss, epoch, model, optimizer, criterion):\n",
        "      if current_valid_loss < self.best_valid_loss:\n",
        "        self.best_valid_loss = current_valid_loss\n",
        "        print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "        print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "        torch.save({'epoch': epoch+1,'model_state_dict': model.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss': criterion}, 'weights_only.pth')\n",
        "    \n",
        "    \n",
        "      \n",
        "\n",
        "# initialize SaveBestModel class\n",
        "save_best_model = SaveBestModel()\n",
        "            "
      ],
      "metadata": {
        "id": "P0p7wNkIkmof"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(epochs, model, optimizer, criterion) :\n",
        "      \"\"\"\n",
        "      Function to save the trained model to disk.\n",
        "      \"\"\"\n",
        "      print(f\"Saving final model...\")\n",
        "      torch.save({'epoch': epochs,'model_state_dict': model.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss': criterion}, 'weights_only.pth')\n",
        "      #We will call this function after the training iterations for all the epochs are complete.\n"
      ],
      "metadata": {
        "id": "aqOkZYnqkmrD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plots(train_loss, valid_loss):\n",
        "      \"\"\"\n",
        "      Function to save the loss plots to disk.\n",
        "      \"\"\"\n",
        "      \n",
        "      \n",
        "      # loss plots\n",
        "      plt.figure(figsize=(10, 7))\n",
        "      plt.plot(train_loss, color='orange', linestyle='-', label='train loss')\n",
        "      plt.plot(valid_loss, color='red', linestyle='-', label='validataion loss')\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Loss')\n",
        "      plt.legend()\n",
        "      #plt.savefig('outputs/loss.png')"
      ],
      "metadata": {
        "id": "pO-qwW4U-SZL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoCKdb8dNM7f"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdGovJsyKiWI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Simple CNN\n",
        "class Net(nn.Module):\n",
        "    # Constructor\n",
        "    def __init__(self, in_size, n_hidden, out_size, p=0.5):\n",
        "      super(Net, self).__init__()\n",
        "      self.drop = nn.Dropout(p=p)\n",
        "      self.linear1 = nn.Linear(in_size, n_hidden)\n",
        "      self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
        "      self.linear3 = nn.Linear(n_hidden, out_size)\n",
        "\n",
        "      \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "      # x = F.relu(self.drop(self.linear1(x))).to(device)\n",
        "      \n",
        "      x = self.linear1(x)\n",
        "      x = self.drop(x)\n",
        "      x = F.relu(x)\n",
        "\n",
        "      x = F.relu(self.drop(self.linear2(x)))\n",
        "      x = self.linear3(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISFPQkU2LFNa",
        "outputId": "82508a6d-b7e4-4097-fcf9-3c14d6f5088d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9gENmoANqXD"
      },
      "source": [
        "# Pre-training: Loaders, Helper Functions & Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJkTl85BNc_n"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_loader = DataLoader(data_set, shuffle= True, batch_size = batch_size)\n",
        "validation_loader = DataLoader(Data(train= False), shuffle = True, batch_size = batch_size) #use percent of data for validation\n",
        "#val_xtrain = (validation_set.x).to(device=device)\n",
        "#val_ytrain = (validation_set.y).to(device=device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YZhG2b4NdCL",
        "outputId": "09316720-ff42-4112-f667-75eb7987f541"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              "  (linear1): Linear(in_features=1, out_features=800, bias=True)\n",
              "  (linear2): Linear(in_features=800, out_features=800, bias=True)\n",
              "  (linear3): Linear(in_features=800, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "# Initialize network\n",
        "#model = Net(1,500,1).to(device)\n",
        "model_drop = Net(1, 800, 1, p=0.5).to(device)\n",
        "#model.train()\n",
        "model_drop.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5G7z-gFp3jk"
      },
      "outputs": [],
      "source": [
        "# Set the optimizer and criterion(loss) function\n",
        "\n",
        "\n",
        "optimizer_drop = torch.optim.Adam(model_drop.parameters(), learning_rate)\n",
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4sXyiV7p3oh"
      },
      "outputs": [],
      "source": [
        "data = (data_set.x).to(device=device)\n",
        "target = (data_set.y).to(device=device)\n",
        "#val_xtrain = (validation_set.x).to(device=device)\n",
        "#val_ytrain = (validation_set.y).to(device=device)\n",
        "\n",
        "\n",
        "\n",
        "def train(model, trainloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    #print('Training')\n",
        "    train_running_loss = 0.0\n",
        "    counter = 0\n",
        "    for x,y in train_loader:\n",
        " \n",
        "        # forward pass\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)  \n",
        "        outputs = model(x)\n",
        "        # calculate the loss\n",
        "        loss = criterion(outputs, y)\n",
        "        train_running_loss += loss.item()\n",
        "        counter += x.shape[0]\n",
        "        \n",
        "        # backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # update the optimizer parameters\n",
        "        optimizer.step()\n",
        "    \n",
        "    # loss for the complete epoch\n",
        "    epoch_loss = train_running_loss / counter\n",
        "    \n",
        "    return epoch_loss\n",
        "\n",
        "# validation : rem our validation loader is called 'validation_set'\n",
        "def validate(model, testloader, criterion):\n",
        "    model.eval()\n",
        "    #print('Validation')\n",
        "    valid_running_loss = 0.0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for x,y in testloader:\n",
        "            \n",
        "            # forward pass\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)  \n",
        "            outputs = model(x)\n",
        "            # calculate the loss\n",
        "            loss = criterion(outputs, y)\n",
        "            valid_running_loss += loss.item()\n",
        "            counter += x.shape[0]\n",
        "            \n",
        "            \n",
        "        \n",
        "    # loss for the complete epoch\n",
        "    epoch_loss = valid_running_loss / counter\n",
        "    \n",
        "    \n",
        "    return epoch_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X9kmyXWzAHTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vtyudoFqDHZ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lists to keep track of losses and accuracies\n",
        "train_loss, valid_loss = [], []\n",
        "\n",
        "# start the training\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[INFO]: Epoch {epoch+1} of {num_epochs}\")\n",
        "    train_epoch_loss = train(model_drop, train_loader,optimizer_drop, criterion)\n",
        "    valid_epoch_loss = validate(model_drop, validation_set, criterion)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "    \n",
        "    print(f\"Training loss: {train_epoch_loss:.3f}\")\n",
        "    print(f\"Validation loss: {valid_epoch_loss:.3f}\")\n",
        "    # save the best model till now if we have the least loss in the current epoch\n",
        "    save_best_model(valid_epoch_loss, epoch, model_drop, optimizer_drop, criterion)\n",
        "    print('-'*50)\n",
        "    \n",
        "# save the trained model weights for a final time\n",
        "save_model(num_epochs, model_drop, optimizer_drop, criterion)\n",
        "# save the loss and accuracy plots\n",
        "save_plots(train_loss, valid_loss)\n",
        "print('TRAINING COMPLETE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v5VJE9NgyLwh",
        "outputId": "94624229-91c4-4916-b3e6-5048b745371d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Epoch 1 of 1200\n",
            "Training loss: 0.001\n",
            "Validation loss: 0.001\n",
            "\n",
            "Best validation loss: 0.0008674070332199335\n",
            "\n",
            "Saving best model for epoch: 1\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 2 of 1200\n",
            "Training loss: 0.001\n",
            "Validation loss: 0.001\n",
            "\n",
            "Best validation loss: 0.0007816638421267271\n",
            "\n",
            "Saving best model for epoch: 2\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 3 of 1200\n",
            "Training loss: 0.001\n",
            "Validation loss: 0.001\n",
            "\n",
            "Best validation loss: 0.0006915916403755545\n",
            "\n",
            "Saving best model for epoch: 3\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 4 of 1200\n",
            "Training loss: 0.001\n",
            "Validation loss: 0.001\n",
            "\n",
            "Best validation loss: 0.0006173386780545116\n",
            "\n",
            "Saving best model for epoch: 4\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 5 of 1200\n",
            "Training loss: 0.001\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.0004063325146213174\n",
            "\n",
            "Saving best model for epoch: 5\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 6 of 1200\n",
            "Training loss: 0.001\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.0003243944155983627\n",
            "\n",
            "Saving best model for epoch: 6\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 7 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.0003180642321705818\n",
            "\n",
            "Saving best model for epoch: 7\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 8 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.00022190291779115796\n",
            "\n",
            "Saving best model for epoch: 8\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 9 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 10 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.00016778292856179178\n",
            "\n",
            "Saving best model for epoch: 10\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 11 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.00014580853711813687\n",
            "\n",
            "Saving best model for epoch: 11\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 12 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.0001394754960667342\n",
            "\n",
            "Saving best model for epoch: 12\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 13 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.00013735618419013918\n",
            "\n",
            "Saving best model for epoch: 13\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 14 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 15 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 0.00013152138353325426\n",
            "\n",
            "Saving best model for epoch: 15\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 16 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 7.043176947627216e-05\n",
            "\n",
            "Saving best model for epoch: 16\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 17 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 4.401324277278036e-05\n",
            "\n",
            "Saving best model for epoch: 17\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 18 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 19 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 20 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 21 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 3.399766975780949e-05\n",
            "\n",
            "Saving best model for epoch: 21\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 22 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 23 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 24 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 3.007244048640132e-05\n",
            "\n",
            "Saving best model for epoch: 24\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 25 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 26 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 27 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 28 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 29 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 30 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 2.6362147135660053e-05\n",
            "\n",
            "Saving best model for epoch: 30\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 31 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 32 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 33 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 34 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 35 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 36 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 37 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 38 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 39 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 2.6306281459983438e-05\n",
            "\n",
            "Saving best model for epoch: 39\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 40 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 41 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 2.5875106832245363e-05\n",
            "\n",
            "Saving best model for epoch: 41\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 42 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 43 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 44 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 45 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 1.9310348283033818e-05\n",
            "\n",
            "Saving best model for epoch: 45\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 46 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 47 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 1.6815413977019488e-05\n",
            "\n",
            "Saving best model for epoch: 47\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 48 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 49 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 50 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 51 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 52 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 53 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 54 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 55 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 56 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 57 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 58 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 59 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 60 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 61 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 62 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 63 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 64 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 65 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 66 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 67 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 68 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 69 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 1.6050314984750004e-05\n",
            "\n",
            "Saving best model for epoch: 69\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 70 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 71 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 72 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 73 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 74 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 75 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 76 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 77 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 78 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 1.4794862098642625e-05\n",
            "\n",
            "Saving best model for epoch: 78\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 79 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 80 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 81 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 82 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 83 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 84 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 1.311021521105431e-05\n",
            "\n",
            "Saving best model for epoch: 84\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 85 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 86 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 87 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 88 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 89 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 90 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 91 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 92 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 93 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 94 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 95 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 96 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 97 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 98 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 99 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 100 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 101 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 102 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 103 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 104 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 105 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 106 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 107 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 108 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 109 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 110 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 111 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 1.2033308518584818e-05\n",
            "\n",
            "Saving best model for epoch: 111\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 112 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 113 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 114 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 115 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 116 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 117 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 118 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 119 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 120 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 121 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 122 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 123 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 1.1140960050397552e-05\n",
            "\n",
            "Saving best model for epoch: 123\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 124 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 125 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 126 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 127 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 128 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 129 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 130 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 131 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 132 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 133 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 134 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 9.455684910062701e-06\n",
            "\n",
            "Saving best model for epoch: 134\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 135 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 136 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 137 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 138 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 139 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 140 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 141 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 142 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 143 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 144 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 145 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 146 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 147 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 148 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 8.249569297186099e-06\n",
            "\n",
            "Saving best model for epoch: 148\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 149 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 150 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 151 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 152 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 153 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 154 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 155 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 156 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 157 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 158 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 159 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 160 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 161 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 162 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 163 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 164 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 165 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 166 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 8.176864957204088e-06\n",
            "\n",
            "Saving best model for epoch: 166\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 167 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 168 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 169 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 170 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 171 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 172 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 173 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 174 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 175 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 176 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 177 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 178 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 179 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 180 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 181 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 182 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 183 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 184 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 185 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 186 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 187 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 188 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 189 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 190 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 191 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 192 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 193 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 194 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 195 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 196 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 197 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 198 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 199 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 200 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 201 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 202 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 203 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 204 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 205 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 206 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 207 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 208 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 209 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 210 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 211 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 212 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 213 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 214 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 215 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 216 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 217 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 218 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 219 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 220 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 221 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 222 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 223 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 224 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 225 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 226 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 8.053090720204636e-06\n",
            "\n",
            "Saving best model for epoch: 226\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 227 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 228 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 229 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 230 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 231 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 232 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 233 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 234 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 235 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 236 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 237 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 238 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 239 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 240 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 241 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 242 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 243 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 244 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 245 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 246 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 247 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 248 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 249 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 250 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 251 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 252 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 253 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 254 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 255 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 256 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 257 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 258 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 259 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 260 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 261 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 262 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 263 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 264 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 265 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 266 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 267 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 7.590635085944087e-06\n",
            "\n",
            "Saving best model for epoch: 267\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 268 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 269 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 270 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 271 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 272 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 273 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 274 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 275 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 276 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 277 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 278 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 279 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 280 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 281 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 282 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 283 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 284 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 285 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 286 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 287 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 288 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 289 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 290 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 291 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 292 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 293 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 294 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 295 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 296 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 297 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 298 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 299 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 300 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 301 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 302 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 303 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 304 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 305 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 306 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 307 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 308 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 6.935053519555368e-06\n",
            "\n",
            "Saving best model for epoch: 308\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 309 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 310 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 311 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 312 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 313 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 314 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 315 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 316 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 317 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 318 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 319 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 320 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 321 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 322 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 323 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 324 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 325 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 326 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 327 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 328 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 329 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 330 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 331 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 332 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 333 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 334 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 335 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 336 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 337 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 338 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 339 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 340 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 341 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 342 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 343 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 344 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 345 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 346 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 347 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 348 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 349 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 350 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 351 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 352 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 353 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 354 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 355 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 356 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 357 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 358 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 359 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 360 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 361 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 362 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 363 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 364 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 365 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 366 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 367 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 368 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 369 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 370 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 371 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 372 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 373 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 374 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 375 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 376 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 377 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 378 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 379 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 380 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 381 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 382 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 383 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 384 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 385 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 386 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 387 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 388 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 389 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 390 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 391 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 392 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 393 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 394 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 395 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 396 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 397 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 398 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 399 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 400 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 401 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 402 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 403 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 404 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 405 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 406 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 407 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 408 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 409 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 410 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 411 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 412 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 413 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 414 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 415 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 416 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 417 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 418 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 419 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 420 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 421 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 422 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 423 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 424 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 425 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 426 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 427 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 428 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 429 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 430 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 431 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 432 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 433 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 434 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 435 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 436 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 437 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 438 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 439 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 440 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 441 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 442 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 443 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 444 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 445 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 446 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 447 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 448 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 449 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 6.78937707998557e-06\n",
            "\n",
            "Saving best model for epoch: 449\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 450 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 451 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 452 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 453 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 454 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 455 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 456 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 457 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 458 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 459 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 460 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 461 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 462 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 463 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 464 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 465 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 466 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 467 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 468 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 469 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 470 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 471 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 472 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 473 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 474 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 475 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 476 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 477 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 478 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 479 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 480 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 481 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 482 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 483 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 484 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 485 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 6.076795687840786e-06\n",
            "\n",
            "Saving best model for epoch: 485\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 486 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 487 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 488 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 489 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 490 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 491 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 492 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 493 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 494 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 495 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 496 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 497 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 498 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 499 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 500 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 501 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 502 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 503 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 504 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 505 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 506 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 507 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 508 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 509 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 510 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 511 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 512 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 513 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 514 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 515 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 516 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 517 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 518 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 519 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 520 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 521 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 522 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 523 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 524 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 525 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 526 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 527 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 528 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 529 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 530 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 531 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 532 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 533 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 534 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 535 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 536 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 537 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 538 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 539 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 540 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 541 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 542 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 543 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 544 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 545 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 546 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 547 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 548 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 549 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 550 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 551 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 552 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 553 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 554 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 555 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 556 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 557 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 558 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 559 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 560 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 561 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 562 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 563 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 564 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 565 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 566 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 567 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 568 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 569 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 570 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 571 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 572 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 573 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 574 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 575 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 576 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 577 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 578 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 579 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 580 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 581 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 582 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 583 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 584 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 585 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 586 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 587 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 588 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 589 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 590 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 591 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 592 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 593 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 594 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 595 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 596 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 597 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 598 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 599 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 600 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 601 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 602 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 5.998356605414301e-06\n",
            "\n",
            "Saving best model for epoch: 602\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 603 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 604 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 605 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 606 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 607 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 608 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 609 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 610 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 611 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 612 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 613 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 614 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 615 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 616 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 617 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 618 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 619 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 620 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 621 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 622 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 623 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 624 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 625 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 626 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 627 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 628 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 629 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 630 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 631 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 632 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 633 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 634 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 635 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 636 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 637 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 638 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 639 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 640 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 641 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 642 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 643 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 644 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 645 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 646 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 647 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 648 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 649 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 650 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 651 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 652 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 653 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 654 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 655 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 656 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 657 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 658 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 659 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 660 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 661 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 662 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 663 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 664 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 665 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 666 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 667 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 668 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 669 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 670 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 671 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 672 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 673 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 674 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 675 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 676 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 677 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 678 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 679 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 680 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 681 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 682 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 683 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 684 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 685 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 686 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 687 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 688 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 689 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 690 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 691 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 692 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 693 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 694 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 695 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 696 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 697 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 698 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 699 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 700 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 701 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 702 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 703 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 704 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 705 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 706 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 707 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 708 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 709 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 710 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 711 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 712 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 713 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 714 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 715 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 716 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 717 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "\n",
            "Best validation loss: 4.691241041291505e-06\n",
            "\n",
            "Saving best model for epoch: 717\n",
            "\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 718 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 719 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 720 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 721 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 722 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 723 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 724 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 725 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 726 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 727 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 728 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 729 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 730 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 731 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 732 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 733 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 734 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 735 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 736 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 737 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 738 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 739 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 740 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 741 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 742 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 743 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 744 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 745 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 746 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 747 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 748 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 749 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 750 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 751 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 752 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 753 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 754 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 755 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 756 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 757 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 758 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 759 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 760 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 761 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 762 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 763 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 764 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 765 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 766 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 767 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 768 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 769 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 770 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 771 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 772 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 773 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 774 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 775 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 776 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 777 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 778 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 779 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 780 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 781 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 782 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 783 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 784 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 785 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 786 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 787 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 788 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 789 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 790 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 791 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 792 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 793 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 794 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 795 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 796 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 797 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 798 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 799 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 800 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 801 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 802 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 803 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 804 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 805 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 806 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 807 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 808 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 809 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 810 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 811 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 812 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 813 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 814 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 815 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 816 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 817 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 818 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 819 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 820 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 821 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 822 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 823 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 824 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 825 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 826 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 827 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 828 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 829 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 830 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 831 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 832 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 833 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 834 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 835 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 836 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 837 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 838 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 839 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 840 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 841 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 842 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 843 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 844 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 845 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 846 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 847 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 848 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 849 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 850 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 851 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 852 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 853 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 854 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 855 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 856 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 857 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 858 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 859 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 860 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 861 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 862 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 863 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 864 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 865 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 866 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 867 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 868 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 869 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 870 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 871 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 872 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 873 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 874 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 875 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 876 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 877 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 878 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 879 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 880 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 881 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 882 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 883 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 884 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 885 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 886 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 887 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 888 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 889 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 890 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 891 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 892 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 893 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 894 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 895 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 896 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 897 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 898 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 899 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 900 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 901 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 902 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 903 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 904 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 905 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 906 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 907 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 908 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 909 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 910 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 911 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 912 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 913 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 914 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 915 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 916 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 917 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 918 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 919 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 920 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 921 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 922 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 923 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 924 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 925 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 926 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 927 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 928 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 929 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 930 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 931 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 932 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 933 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 934 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 935 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 936 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 937 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 938 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 939 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 940 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 941 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 942 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 943 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 944 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 945 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 946 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 947 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 948 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 949 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 950 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 951 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 952 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 953 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 954 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 955 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 956 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 957 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 958 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 959 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 960 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 961 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 962 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 963 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 964 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 965 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 966 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 967 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 968 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 969 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 970 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 971 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 972 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 973 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 974 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 975 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 976 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 977 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 978 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 979 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 980 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 981 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 982 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 983 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 984 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 985 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 986 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 987 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 988 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 989 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 990 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 991 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 992 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 993 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 994 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 995 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 996 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 997 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 998 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 999 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1000 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1001 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1002 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1003 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1004 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1005 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1006 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1007 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1008 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1009 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1010 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1011 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1012 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1013 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1014 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1015 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1016 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1017 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1018 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1019 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1020 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1021 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1022 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1023 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1024 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1025 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1026 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1027 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1028 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1029 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1030 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1031 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1032 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1033 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1034 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1035 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1036 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1037 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1038 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1039 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1040 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1041 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1042 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1043 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1044 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1045 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1046 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1047 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1048 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1049 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1050 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1051 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1052 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1053 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1054 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1055 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1056 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1057 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1058 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1059 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1060 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1061 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1062 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1063 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1064 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1065 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1066 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1067 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1068 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1069 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1070 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1071 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1072 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1073 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1074 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1075 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1076 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1077 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1078 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1079 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1080 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1081 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1082 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1083 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1084 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1085 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1086 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1087 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1088 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1089 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1090 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1091 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1092 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1093 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1094 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1095 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1096 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1097 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1098 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1099 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1100 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1101 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1102 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1103 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1104 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1105 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1106 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1107 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1108 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1109 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1110 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1111 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1112 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1113 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1114 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1115 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1116 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1117 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1118 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1119 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1120 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1121 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1122 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1123 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1124 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1125 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1126 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1127 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1128 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1129 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1130 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1131 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1132 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1133 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1134 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1135 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1136 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1137 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1138 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1139 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1140 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1141 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1142 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1143 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1144 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1145 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1146 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1147 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1148 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1149 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1150 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1151 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1152 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1153 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1154 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1155 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1156 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1157 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1158 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1159 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1160 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1161 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1162 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1163 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1164 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1165 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1166 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1167 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1168 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1169 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1170 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1171 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1172 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1173 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1174 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1175 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1176 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1177 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1178 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1179 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1180 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1181 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1182 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1183 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1184 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1185 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1186 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1187 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1188 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1189 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1190 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1191 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1192 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1193 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1194 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1195 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1196 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1197 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1198 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1199 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "[INFO]: Epoch 1200 of 1200\n",
            "Training loss: 0.000\n",
            "Validation loss: 0.000\n",
            "--------------------------------------------------\n",
            "Saving final model...\n",
            "TRAINING COMPLETE\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis:\n",
        "\n",
        "#Set the model with dropout to evaluation mode\n",
        "\n",
        "#model_drop.eval()\n",
        "\n",
        "# Make the prediction\n",
        "#output = model_drop(data)\n",
        "#plt.plot(data.to(\"cpu\").numpy(), data_set.f.numpy(),label=\"True function\", color='orange')\n",
        "#plt.plot(data.to(\"cpu\").numpy(), output.to(\"cpu\").detach().numpy() , label=\"Plot after training data\", c ='g')\n",
        "#plt.title('Plot of trained versus true models of a complex trigonometric function')\n",
        "#plt.xlabel(\"x\")\n",
        "#plt.ylabel(\"y\")\n",
        "#plt.xlim((-1, 1))\n",
        "#plt.ylim((-2, 2.5))\n",
        "#plt.legend(loc = \"best\")\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "Vzo5DOF9yL1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "X_test = data\n",
        "X_test = (data)\n",
        "with torch.inference_mode(): \n",
        "    y_preds = model_drop(X_test)\n",
        "\n",
        "print(f\"Number of testing samples: {len(X_test)}\") \n",
        "print(f\"Number of predictions made: {len(y_preds)}\")\n",
        "print(f\"Predicted values:\\n{y_preds}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHFVD1KEyL8_",
        "outputId": "b369ff1e-df3d-4e0f-f204-0f3eb91b0a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of testing samples: 10000\n",
            "Number of predictions made: 10000\n",
            "Predicted values:\n",
            "tensor([[-0.3170],\n",
            "        [-0.3162],\n",
            "        [-0.3154],\n",
            "        ...,\n",
            "        [-0.2940],\n",
            "        [-0.2943],\n",
            "        [-0.2945]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZxYQTnUXKQat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = data[1000]\n",
        "b =  (a)*torch.sin(20*a) - ((a)**2)*torch.cos(10*a)\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPLTnTvsKQc1",
        "outputId": "b8aef7e0-6af5-43c7-d265-14b0a0135b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5003], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds[1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVLRlQj8KQfJ",
        "outputId": "7990c2e5-f060-4bfd-8bc4-82b97430314e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5141], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion(data[1000],y_preds[1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyGl70DqKQhf",
        "outputId": "1a07598a-b2f4-4449-c0f6-03cbf99ace9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8355, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis:\n",
        "\n",
        "#Set the model with dropout to evaluation mode\n",
        "\n",
        "model_drop.eval()\n",
        "\n",
        "# Make the prediction\n",
        "output = model_drop(data)\n",
        "plt.plot(data.to(\"cpu\").numpy(), data_set.f.numpy(),label=\"True function\", color='orange')\n",
        "plt.plot(data.to(\"cpu\").numpy(), output.to(\"cpu\").detach().numpy() , label=\"Plot after training data\", c ='g')\n",
        "#plt.title('Plot of trained versus true models of a complex trigonometric function')\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.xlim((-1, 1))\n",
        "plt.ylim((-2, 2.5))\n",
        "plt.legend(loc = \"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "0cTgd_xUMvlI",
        "outputId": "37fd063a-c15a-4db3-88e3-c4ac1d835e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SWDZGM5wMvoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keystones: optimizer zero grad"
      ],
      "metadata": {
        "id": "Z6SvRv4mMvs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "esdpiv-mMvu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "svKnG45MMvxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t_D1uTTOMvzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xw4ADw99KQjk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Preposter - ML Model .ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPhlEx8TJ4CVVLAZJzVadqX",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}